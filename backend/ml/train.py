import os
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
from torch.utils.data import Dataset, DataLoader
import random
import shutil

class ZombieDataset(Dataset):
    def __init__(self, root_dir, transform=None, train=True, valid_split=0.2):
        """ã‚¾ãƒ³ãƒ“åˆ†é¡ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
        
        Args:
            root_dir: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            transform: é©ç”¨ã™ã‚‹å¤‰æ›
            train: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‹
            valid_split: æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ
        """
        self.root_dir = Path(root_dir)
        self.transform = transform
        self.train = train
        self.valid_split = valid_split
        
        # ã‚¯ãƒ©ã‚¹ã‚’å–å¾—
        self.classes = [d.name for d in self.root_dir.iterdir() if d.is_dir()]
        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}
        
        # ç”»åƒãƒ‘ã‚¹ã¨ãƒ©ãƒ™ãƒ«ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        self.images = []
        for cls in self.classes:
            class_dir = self.root_dir / cls
            for img_path in class_dir.glob('*.png'):
                self.images.append((img_path, self.class_to_idx[cls]))
        
        # è¨“ç·´/æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
        random.seed(42)
        random.shuffle(self.images)
        
        split_idx = int(len(self.images) * (1 - valid_split))
        if train:
            self.images = self.images[:split_idx]
        else:
            self.images = self.images[split_idx:]
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        img_path, label = self.images[idx]
        image = Image.open(img_path).convert('RGB')
        
        if self.transform:
            image = self.transform(image)
        
        return image, label

class ZombieClassifier:
    def __init__(self, data_path='../data/datasets/zombie_classifier'):
        """ã‚¾ãƒ³ãƒ“åˆ†é¡å™¨ã®åˆæœŸåŒ–
        
        Args:
            data_path: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¸ã®ãƒ‘ã‚¹
        """
        self.data_path = Path(data_path)
        self.model_path = Path('models')
        self.model_path.mkdir(exist_ok=True)
        self.model = None
        self.classes = ['not_zombie', 'zombie']  # ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«
        
        # GPUãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
        
        # å¤‰æ›ã®å®šç¾©
        self.train_transform = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
            transforms.RandomHorizontalFlip(),
            transforms.RandomRotation(20),
            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        self.valid_transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
    
    def prepare_data(self, batch_size=8):
        """ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ã¨DataLoaderã®ä½œæˆ
        
        Args:
            batch_size: ãƒãƒƒãƒã‚µã‚¤ã‚º
        """
        # ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã®ç¢ºèª
        print(f"ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹: {self.data_path} (å­˜åœ¨: {self.data_path.exists()})")
        
        if not self.data_path.exists():
            raise FileNotFoundError(f"ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ {self.data_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            
        # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª
        subdirs = [d for d in self.data_path.iterdir() if d.is_dir()]
        if not subdirs:
            raise FileNotFoundError(f"ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ {self.data_path} å†…ã«ã‚¯ãƒ©ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        
        print(f"ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {[d.name for d in subdirs]}")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ
        train_dataset = ZombieDataset(self.data_path, transform=self.train_transform, train=True)
        valid_dataset = ZombieDataset(self.data_path, transform=self.valid_transform, train=False)
        
        # DataLoaderã®ä½œæˆ
        self.train_loader = DataLoader(
            train_dataset, 
            batch_size=batch_size, 
            shuffle=True,
            num_workers=0
        )
        
        self.valid_loader = DataLoader(
            valid_dataset, 
            batch_size=batch_size, 
            shuffle=False,
            num_workers=0
        )
        
        # ã‚¯ãƒ©ã‚¹æƒ…å ±ã®ä¿å­˜
        self.classes = train_dataset.classes
        print(f"ã‚¯ãƒ©ã‚¹: {self.classes}")
        
        return self.train_loader, self.valid_loader
    
    def train(self, epochs=10, lr=1e-4):
        """ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
        
        Args:
            epochs: å­¦ç¿’ã‚¨ãƒãƒƒã‚¯æ•°
            lr: å­¦ç¿’ç‡
        """
        # ResNet18ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ
        self.model = models.resnet18(weights='IMAGENET1K_V1')
        
        # æœ€çµ‚å±¤ã‚’ç½®ãæ›ãˆ
        num_ftrs = self.model.fc.in_features
        self.model.fc = nn.Linear(num_ftrs, len(self.classes))
        
        # GPUã«è»¢é€
        self.model = self.model.to(self.device)
        
        # æå¤±é–¢æ•°ã¨æœ€é©åŒ–æ‰‹æ³•ã®è¨­å®š
        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)
        
        # å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='min', factor=0.5, patience=2, verbose=True
        )
        
        # å­¦ç¿’å±¥æ­´
        history = {'train_loss': [], 'train_acc': [], 'valid_loss': [], 'valid_acc': []}
        best_valid_acc = 0
        
        # å­¦ç¿’ãƒ«ãƒ¼ãƒ—
        print(f"é–‹å§‹: {epochs}ã‚¨ãƒãƒƒã‚¯ã®å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...")
        for epoch in range(epochs):
            # è¨“ç·´ãƒ•ã‚§ãƒ¼ã‚º
            self.model.train()
            train_loss = 0
            train_correct = 0
            train_total = 0
            
            for inputs, labels in self.train_loader:
                inputs, labels = inputs.to(self.device), labels.to(self.device)
                
                # å‹¾é…ã‚’ã‚¼ãƒ­ã«ãƒªã‚»ãƒƒãƒˆ
                optimizer.zero_grad()
                
                # é †ä¼æ’­ã€é€†ä¼æ’­ã€æœ€é©åŒ–
                outputs = self.model(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                
                # çµ±è¨ˆæƒ…å ±ã®æ›´æ–°
                train_loss += loss.item() * inputs.size(0)
                _, predicted = torch.max(outputs, 1)
                train_total += labels.size(0)
                train_correct += (predicted == labels).sum().item()
            
            # ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®è¨“ç·´æå¤±ã¨ç²¾åº¦
            train_loss = train_loss / train_total
            train_acc = train_correct / train_total
            
            # æ¤œè¨¼ãƒ•ã‚§ãƒ¼ã‚º
            self.model.eval()
            valid_loss = 0
            valid_correct = 0
            valid_total = 0
            
            with torch.no_grad():
                for inputs, labels in self.valid_loader:
                    inputs, labels = inputs.to(self.device), labels.to(self.device)
                    
                    # é †ä¼æ’­
                    outputs = self.model(inputs)
                    loss = criterion(outputs, labels)
                    
                    # çµ±è¨ˆæƒ…å ±ã®æ›´æ–°
                    valid_loss += loss.item() * inputs.size(0)
                    _, predicted = torch.max(outputs, 1)
                    valid_total += labels.size(0)
                    valid_correct += (predicted == labels).sum().item()
            
            # ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®æ¤œè¨¼æå¤±ã¨ç²¾åº¦
            valid_loss = valid_loss / valid_total
            valid_acc = valid_correct / valid_total
            
            # å­¦ç¿’ç‡ã®èª¿æ•´
            scheduler.step(valid_loss)
            
            # çµæœã®è¡¨ç¤º
            print(f"Epoch {epoch+1}/{epochs} | "
                  f"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | "
                  f"Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.4f}")
            
            # å±¥æ­´ã®æ›´æ–°
            history['train_loss'].append(train_loss)
            history['train_acc'].append(train_acc)
            history['valid_loss'].append(valid_loss)
            history['valid_acc'].append(valid_acc)
            
            # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
            if valid_acc > best_valid_acc:
                best_valid_acc = valid_acc
                model_path = self.model_path/'zombie_classifier.pth'
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': self.model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'train_loss': train_loss,
                    'valid_loss': valid_loss,
                    'valid_acc': valid_acc,
                    'classes': self.classes
                }, model_path)
                print(f"ç²¾åº¦å‘ä¸Š: ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {model_path}")
        
        print(f"å®Œäº†: å­¦ç¿’å®Œäº†ï¼æœ€çµ‚ç²¾åº¦: {valid_acc:.4f}")
        return self.model, history
    
    def evaluate(self):
        """ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡"""
        if self.model is None:
            print("ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚train()ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return
        
        # æ··åŒè¡Œåˆ—ã®ãƒ‡ãƒ¼ã‚¿åé›†
        self.model.eval()
        y_true = []
        y_pred = []
        
        with torch.no_grad():
            for inputs, labels in self.valid_loader:
                inputs, labels = inputs.to(self.device), labels.to(self.device)
                outputs = self.model(inputs)
                _, predicted = torch.max(outputs, 1)
                
                y_true.extend(labels.cpu().numpy())
                y_pred.extend(predicted.cpu().numpy())
        
        # æ··åŒè¡Œåˆ—ã®è¡¨ç¤º
        from sklearn.metrics import confusion_matrix, classification_report
        import seaborn as sns
        
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=self.classes, yticklabels=self.classes)
        plt.xlabel('äºˆæ¸¬')
        plt.ylabel('å®Ÿéš›')
        plt.title('æ··åŒè¡Œåˆ—')
        plt.savefig('confusion_matrix.png')
        
        # åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆã®è¡¨ç¤º
        report = classification_report(y_true, y_pred, target_names=self.classes)
        print("åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ:")
        print(report)
        
        # ç²¾åº¦ã®è¨ˆç®—
        correct = sum(p == t for p, t in zip(y_pred, y_true))
        total = len(y_true)
        accuracy = correct / total
        print(f"ğŸ“Š æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®ç²¾åº¦: {accuracy:.4f}")
        
        return accuracy
    
    def predict_image(self, img_path):
        """ç”»åƒã®äºˆæ¸¬
        
        Args:
            img_path: äºˆæ¸¬ã™ã‚‹ç”»åƒã®ãƒ‘ã‚¹
            
        Returns:
            äºˆæ¸¬ã‚¯ãƒ©ã‚¹, ä¿¡é ¼åº¦
        """
        if self.model is None:
            try:
                # ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
                model_path = self.model_path/'zombie_classifier.pth'
                checkpoint = torch.load(model_path)
                
                # ResNet18ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ
                self.model = models.resnet18(weights=None)
                num_ftrs = self.model.fc.in_features
                self.model.fc = nn.Linear(num_ftrs, len(self.classes))
                
                # ä¿å­˜ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
                self.model.load_state_dict(checkpoint['model_state_dict'])
                self.model.to(self.device)
                self.model.eval()
                
                print(f"ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {model_path}")
            except Exception as e:
                print(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                return None, 0.0
        
        try:
            # ç”»åƒã®å‰å‡¦ç†
            img = Image.open(img_path).convert('RGB')
            image_tensor = self.valid_transform(img).unsqueeze(0).to(self.device)
            
            # äºˆæ¸¬ã®å®Ÿè¡Œ
            with torch.no_grad():
                outputs = self.model(image_tensor)
                probabilities = torch.nn.functional.softmax(outputs, dim=1)
                confidence, predicted = torch.max(probabilities, 1)
                
            # çµæœã®è¿”å´
            predicted_class = self.classes[predicted[0].item()]
            confidence_value = confidence[0].item()
            
            return predicted_class, confidence_value
        
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: ç”»åƒã®äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return None, 0.0

def plot_training_history(history):
    """å­¦ç¿’å±¥æ­´ã‚’ãƒ—ãƒ­ãƒƒãƒˆ"""
    plt.figure(figsize=(12, 4))
    
    # æå¤±ã®ãƒ—ãƒ­ãƒƒãƒˆ
    plt.subplot(1, 2, 1)
    plt.plot(history['train_loss'], label='Train Loss')
    plt.plot(history['valid_loss'], label='Valid Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.title('Training and Validation Loss')
    
    # ç²¾åº¦ã®ãƒ—ãƒ­ãƒƒãƒˆ
    plt.subplot(1, 2, 2)
    plt.plot(history['train_acc'], label='Train Accuracy')
    plt.plot(history['valid_acc'], label='Valid Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.title('Training and Validation Accuracy')
    
    plt.tight_layout()
    plt.savefig('training_history.png')

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼šãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å­¦ç¿’ã¨è©•ä¾¡"""
    # GPUã®çŠ¶æ…‹ã‚’ç¢ºèª
    print(f"CUDAåˆ©ç”¨å¯èƒ½: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"GPUæ•°: {torch.cuda.device_count()}")
        
    # ã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
    classifier = ZombieClassifier()
    
    # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    print("é–‹å§‹: ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...")
    train_loader, valid_loader = classifier.prepare_data(batch_size=8)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ã®è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    def show_batch(loader):
        images, labels = next(iter(loader))
        plt.figure(figsize=(10, 8))
        grid = np.zeros((4*224, 4*224, 3))
        
        for i in range(min(16, len(images))):
            img = images[i].permute(1, 2, 0).cpu().numpy()
            img = (img * [0.229, 0.224, 0.225]) + [0.485, 0.456, 0.406]  # æ­£è¦åŒ–ã‚’æˆ»ã™
            img = np.clip(img, 0, 1)
            
            row = i // 4
            col = i % 4
            grid[row*224:(row+1)*224, col*224:(col+1)*224] = img
            
        plt.imshow(grid)
        plt.axis('off')
        plt.savefig('sample_images.png')
    
    try:
        show_batch(train_loader)
    except:
        print("ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã®è¡¨ç¤ºã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
    
    # ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
    print("ğŸš€ ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...")
    model, history = classifier.train(epochs=8, lr=1e-4)
    
    # å­¦ç¿’å±¥æ­´ã®ãƒ—ãƒ­ãƒƒãƒˆ
    plot_training_history(history)
    
    # ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡
    print("ğŸ“Š ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ã¦ã„ã¾ã™...")
    classifier.evaluate()
    
    # ãƒ†ã‚¹ãƒˆæ¨è«–ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰
    try:
        test_img = list(Path('../data/datasets/zombie_classifier/zombie').glob('*.png'))[0]
        print(f"ğŸ§ª ãƒ†ã‚¹ãƒˆç”»åƒã§ã®æ¨è«–: {test_img}")
        pred_class, prob = classifier.predict_image(test_img)
    except IndexError:
        print("è­¦å‘Š: ãƒ†ã‚¹ãƒˆç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã¯æ­£å¸¸ã«å­¦ç¿’ã•ã‚Œã¦ã„ã¾ã™ã€‚")

if __name__ == "__main__":
    main() 